---
title: Análisis Pobreza Multidimensional
output: html_document
---

```{r}
# Este Notebook se generó siguiendo
# https://rmarkdown.rstudio.com/docs/reference/convert_ipynb.html
# Ejecutando
# nb_rmd = rmarkdown:::convert_ipynb(nb_file)
# donde nb_file <- "AnalisisPobrezaMultidimensional.ipynb"
```


<a href="https://colab.research.google.com/github/Maxmuleiv/Proyecto-Industrial/blob/master/AnalisisPobrezaMultidimensional.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

#1- Importación Packages

```{python}
%reset-f
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
import networkx as nx
from scipy.stats import pointbiserialr
from math import pi
```

```{python}
from google.colab import drive
drive.mount('/content/drive')
```

#2- Importación BD

```{python}
url4="/content/drive/My Drive/CASEN45.csv" #url base datos 
casen = pd.read_csv(url4,";", encoding='iso-8859-1') #importación base datos para calculo tipo hogares y tipologias de las carencias
```

```{python}
#url3="https://github.com/Maxmuleiv/Proyecto-Industrial/blob/master/CASENtipologias.csv?raw=true" #url base datos 
#casen = pd.read_csv(url3,";", encoding='iso-8859-1') #importación base datos para calculo tipo hogares y tipologias de las carencias
```

#3- Categorizacion por tipo de familia

```{python}
casen2=np.array(casen);#print(casen2)
hogares_unicos,hogares_index,hogares_inv,hogares_count=np.unique(casen2[:,0],return_index=True, return_inverse=True, return_counts=True)
n_hogares=len(hogares_unicos)
n_personas=len(casen2[:,0])
cols=np.array(casen[["pco1","numper","tot_nuc"]])

dd=np.zeros((n_hogares,1))
ddd=np.zeros((n_personas,1))
for i,h in enumerate(hogares_unicos):
  #print(h,i)
  miembros=np.where(casen2[:,0]==h)[0]#;print(miembros)
  #n_miembros=len(miembros)
  m_cols=cols[miembros]
  a=0
  if 2 in m_cols[:,0] or 3 in m_cols[:,0]:
    a=1;#print(h,"tiene pareja")
  b=m_cols[0,1]
  c=m_cols[0,2]
  #print(a,b,c)
  if b==1: #hogar unipersonal
    d=1
  elif b==c:
    d=6 #hogar censal   
  elif b>1 and a==0 and c==1:
    d=2 #hogar monoparental nuclear
  elif b>1 and a==1 and c==1:
    d=3 #hogar biparental nuclear
  elif b>1 and a==0 and c>1:
    d=4 #hogar monoparental extendido
  elif b>1 and a==1 and c>1:
    d=5 #hogar biparental extendido
  
  dd[i]=d
  ddd[miembros]=d
# dd es un arreglo por hogar único que indica que tipo de hogar es
# ddd es el tipo de hogar al que pertenecen los miembros
casen["d"]=ddd.astype(int)
#casen.head()
casen.rename(columns = {'Pobreza 5D':'PobMult'}, inplace = True) 
casen=casen[casen.pobreza_multi_5d == "Pobre"]
casen_general=casen.copy()

casen.head()
```

#4- Definición funciones

```{python}
# FUNCION PARA OBTENCION HEATMAPS POR TIPO DE CORRELACION (PEARSON, KENDALL Y SPEARMAN)
def creacion_heatmap(Nombre_metodo,Tabla_variables,Negativos,Comentario_grafico):
  

  if  Negativos==False:
    color_min=-0.01
  else:
    color_min=-0.5
    
  Tabla_correlaciones = Tabla_variables.corr(method=Nombre_metodo)
  plt.figure(figsize = (20,10)) #arreglar el tamaño del gráfico

  mask = np.zeros(Tabla_correlaciones.shape, dtype=bool) #eliminacion datos simetricos
  mask[np.triu_indices(len(mask))] = True

  mapa=sb.heatmap(Tabla_correlaciones.values.round(2), xticklabels=Tabla_correlaciones.columns, # heatmap pearson
            yticklabels=Tabla_correlaciones.columns,vmin =color_min, vmax = 0.5, center = 0, cmap = "RdBu",annot=True, mask=mask, linewidths=3)


#antes fije vmax en 0.12 por si lo quiero volver a poner
  b, t = mapa.get_ylim() # identificar limites de corte
  mapa.set_ylim(b + 0.5, t - 0.5) #redefinir limites de corte
  plt.savefig("Heatmap_"+Nombre_metodo+"_"+Comentario_grafico+".png",bbox_inches="tight")
  plt.savefig("Heatmap_"+Nombre_metodo+"_"+Comentario_grafico+".svg",bbox_inches="tight")

  return
  plt.show()

# set carencias y set dimensiones
jjj=["Asistencia","Rezago escolar","Escolaridad","Malnutricion infantil","Sistema de salud","Atencion","Ocupacion","Seguridad social","Jubilaciones","Habitabilidad","Servicios basicos","Entorno","Apoyo y participacion social","Trato igualitario","Seguridad"]
hhh=["Educacion","Salud","Trabajo y seguridad social","Vivienda y entorno","Redes y cohesion social"]

```

#5- Cálculo correlaciones carencias



```{python}
casen_hogares=casen[["folio","Asistencia","Rezago escolar","Escolaridad","Malnutricion infantil","Sistema de salud","Atencion","Ocupacion","Seguridad social","Jubilaciones","Habitabilidad","Servicios basicos","Entorno","Apoyo y participacion social","Trato igualitario","Seguridad"]]
casen_hogares=casen_hogares.drop_duplicates()
casen_hogares = casen_hogares.drop(['folio'],axis=1)
pearson5d = casen_hogares.corr(method='pearson')
pearson5d
print(len(casen_hogares.index))
print(len(casen.index))
```

```{python}
creacion_heatmap("pearson",casen_hogares,True,"Correlaciones")
```

```{python}
# importacion datos correlaciones excel

pearson5d.to_excel(excel_writer = "pearson5d.xlsx")
```

#6- Cálculo correlaciones por tipo de hogar


```{python}
tipohogares=casen[["folio","Asistencia","Rezago escolar","Escolaridad","Malnutricion infantil","Sistema de salud","Atencion","Ocupacion","Seguridad social","Jubilaciones","Habitabilidad","Servicios basicos","Entorno","Apoyo y participacion social","Trato igualitario","Seguridad","d"]]
tipohogares=tipohogares.drop_duplicates()
t_hogares=len(tipohogares.index)
print("total de hogares =",t_hogares)

hogar_unip=tipohogares[tipohogares.d == 1]
hogar_mononuc=tipohogares[tipohogares.d == 2]
hogar_binuc=tipohogares[tipohogares.d == 3]
hogar_monoex=tipohogares[tipohogares.d == 4]
hogar_biex=tipohogares[tipohogares.d == 5]
hogar_cen=tipohogares[tipohogares.d == 6]


hogar_unip=hogar_unip[jjj]
hogar_mononuc=hogar_mononuc[jjj]
hogar_binuc=hogar_binuc[jjj]
hogar_monoex=hogar_monoex[jjj]
hogar_biex=hogar_biex[jjj]
hogar_cen=hogar_cen[jjj]

t_unip=len(hogar_unip.index)
t_mononuc=len(hogar_mononuc.index)
t_binuc=len(hogar_binuc.index)
t_monoex=len(hogar_monoex.index)
t_biex=len(hogar_biex.index)
t_cen=len(hogar_cen.index)





print("total de hogares =",t_hogares)
print("total de h. unipersonal =",t_unip, "-",round(t_unip*100/t_hogares,2),"%")
print("total de h. monoparental nuclear =",t_mononuc,"-",round(t_mononuc*100/t_hogares,2),"%")
print("total de h. biparental nuclear =",t_binuc,"-",round(t_binuc*100/t_hogares,2),"%")
print("total de h. monoparental extendido =",t_monoex,"-",round(t_monoex*100/t_hogares,2),"%")
print("total de h. biparental extendido =",t_biex,"-",round(t_biex*100/t_hogares,2),"%")
print("total de h. censal =",t_cen,"-",round(t_cen*100/t_hogares,2),"%")


creacion_heatmap("pearson",hogar_unip,True,"Correlaciones")
creacion_heatmap("pearson",hogar_mononuc,True,"Correlaciones")
creacion_heatmap("pearson",hogar_binuc,True,"Correlaciones")
creacion_heatmap("pearson",hogar_monoex,True,"Correlaciones")
creacion_heatmap("pearson",hogar_biex,True,"Correlaciones")
creacion_heatmap("pearson",hogar_cen,True,"Correlaciones")
```

```{python}
print(len(tipohogares.index))
```

#7- Cálculo correlaciones dimensionales (5D)


```{python}
# Calculo de indicador por dimension

dim=tipohogares.copy()
dim["Educacion"]=np.nan
dim["Salud"]=np.nan
dim["Trabajo y seguridad social"]=np.nan
dim["Vivienda y entorno"]=np.nan
dim["Redes y cohesion social"]=np.nan

for p in dim.index:
 # dim[p,"Educacion"]=dim[p,"Asistencia"]
  
  dim['Educacion'][p]=dim['Asistencia'][p]+dim['Rezago escolar'][p]+dim['Escolaridad'][p]
  dim['Salud'][p]=dim['Malnutricion infantil'][p]+dim['Sistema de salud'][p]+dim['Atencion'][p]
  dim['Trabajo y seguridad social'][p]=dim['Ocupacion'][p]+dim['Seguridad social'][p]+dim['Jubilaciones'][p]
  dim['Vivienda y entorno'][p]=dim['Habitabilidad'][p]+dim['Servicios basicos'][p]+dim['Entorno'][p]
  dim['Redes y cohesion social'][p]=dim['Apoyo y participacion social'][p]+dim['Trato igualitario'][p]+dim['Seguridad'][p]
  dim["Educacion"][p]=int(dim["Educacion"][p])
#dim[dim.Educacion == 3]
dim1=dim[["folio","Educacion","Salud","Trabajo y seguridad social","Vivienda y entorno","Redes y cohesion social","d"]]

#casen_hogares=casen[["Asistencia","Rezago escolar","Escolaridad","Malnutricion infantil","Sistema de salud","Atencion","Ocupacion","Seguridad social","Jubilaciones","Habitabilidad","Servicios basicos","Entorno","Apoyo y participacion social","Trato igualitario","Seguridad"]]
```

```{python}
dim2=dim1.drop(['d'],axis=1)
dim2=dim2.drop_duplicates()
dim2=dim2.drop(['folio'],axis=1)
pearsonDim = dim1.corr(method='pearson')
pearsonDim
```

```{python}
# OBTENCION HEATMAPS PEARSON, KENDALL Y SPEARMAN POR DIMENSIONES

creacion_heatmap("pearson",dim2,True,"DIM")
```

```{python}
# exportacion datos correlaciones excel

pearsonDim.to_excel(excel_writer = "pearsonDim.xlsx")
dim.to_excel(excel_writer="hola.xlsx")
```

#8- Cálculo correlaciones dimensionales por hogar


```{python}
dim3=dim1.drop_duplicates()
dim31=dim3[dim3.d==1].drop("d", axis=1)
dim32=dim3[dim3.d==2].drop("d", axis=1)
dim33=dim3[dim3.d==3].drop("d", axis=1)
dim34=dim3[dim3.d==4].drop("d", axis=1)
dim35=dim3[dim3.d==5].drop("d", axis=1)
dim36=dim3[dim3.d==6].drop("d", axis=1)


creacion_heatmap("pearson",dim31,True,"dim_unip")
creacion_heatmap("pearson",dim32,True,"dim_monuc")
creacion_heatmap("pearson",dim33,True,"dim_binuc")
creacion_heatmap("pearson",dim34,True,"dim_moex")
creacion_heatmap("pearson",dim35,True,"dim_biex")
creacion_heatmap("pearson",dim36,True,"dim_cen")
```

#9- Análisis red carencias

```{python}
#transformación datos insice matriz de correlaciones, en este caso se usa pearson
indices = pearson5d.index.values
# transformación datos carencias a matriz, se emplea en este caso pearson
matrizCarencias = np.asmatrix(pearson5d)
#Creación de grafo con datos de la matriz de correlaciones Matriz5d
Gcarencias = nx.from_numpy_matrix(matrizCarencias)

#etiquetado de nosos para que coincidan con nombres de carencias
Gcarencias = nx.relabel_nodes(Gcarencias,lambda x: matrizCarencias[x,x]) # revisar aca, redefinicion de las etiquetas

#Muestra los arcos con sus respectivos pesos
Gcarencias.edges(data=True)
```

```{python}
#Funcion para crear redes en base a correlaciones

def create_corr_network_1(G):
    #creacion lista de arcos y lista de pesos
    edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())

    #Layout circular del grafo
    positions=nx.circular_layout(G)
    
    #Tamaño de la figura
    plt.figure(figsize=(15,15))

    #Ploteo de nodos
    nx.draw_networkx_nodes(G,positions,node_color='#DA70D6',
                           node_size=500,alpha=0.8)
    
    #Estilo etiquetas
    nx.draw_networkx_labels(G, positions, font_size=8, 
                            font_family='sans-serif')
        
    #Ploteo de arcos
    nx.draw_networkx_edges(G, positions, edge_list=edges,style='solid')
    
    # Presentar el gráfico sin eje
    plt.axis('off')
   
    # Importación imagen grafo
    plt.savefig("grafocorr.png", format="PNG")
    plt.savefig("grafocorr.svg", format="SVG")
    plt.show() 
    create_corr_network_1(G)
```

```{python}
# Transform it in a links data frame (3 columns only):
links = pearson5d.stack().reset_index()
links.columns = ['var1', 'var2','value']
links
 
# eliminar correlaciones autorreferenciadas
links_filtered=links.loc[ (links['value'] < 0) & (links['var1'] != links['var2']) ]
links_filtered
 
# Creación gráfico
G=nx.from_pandas_edgelist(links_filtered, 'var1', 'var2')
nx.draw_circular(G, with_labels=True, node_color='cyan', node_size=40, edge_color='black', linewidths=0.01, font_size=12)

#b, t = mapa5d.get_ylim() # identificar limites de corte
#mapa5d.set_ylim(b + 0.5, t - 0.5) #redefinir limites de corte
```

#10- Cálculo coeficiente de determinación R cuadrado para dimensiones

```{python}
dim.head()
```

```{python}
dimensiones2=dim.T
dimensiones2.head()
```

```{python}
# cálculo coef. 
dimensionesR=np.corrcoef(dimensiones2)
```

```{python}
pd.DataFrame(dimensionesR).head()
```

```{python}
# obtención coef. r cuadrado
dimensionesR2=dimensionesR**2
```

```{python}
dimensionesR2=pd.DataFrame(dimensionesR2)
dimensionesR2.head()
```

```{python}
pd.DataFrame(dimensionesR).to_excel(excel_writer = "r.xlsx")
dimensionesR2.to_excel(excel_writer = "r_cuadrado.xlsx")
```

```{python}
dim.cov()
```

#11- Obtención tipologías



```{python}
# calculo frecuencia de cada carencia
suma_carencias=casen_hogares.sum()
suma_carencias
```

```{python}
# dataframe con factores externos

f1="zona" #numero de personas en el hogar
f2="numper" #rural o urbano
f3="ypc"
casen_tip=casen[[f1,f2,f3,"folio","Asistencia","Rezago escolar","Escolaridad","Malnutricion infantil","Sistema de salud","Atencion","Ocupacion","Seguridad social","Jubilaciones","Habitabilidad","Servicios basicos","Entorno","Apoyo y participacion social","Trato igualitario","Seguridad","d"]]
casen_tip=casen_tip.drop_duplicates()
casen_tip=casen_tip.drop("folio",axis=1)
#casen_tip.head()

casen_tip_dim=casen_tip.copy()
casen_tip_dim["Educacion"]=np.nan
casen_tip_dim["Salud"]=np.nan
casen_tip_dim["Trabajo y seguridad social"]=np.nan
casen_tip_dim["Vivienda y entorno"]=np.nan
casen_tip_dim["Redes y cohesion social"]=np.nan

for p in casen_tip_dim.index:
 # dim[p,"Educacion"]=dim[p,"Asistencia"]
  
  casen_tip_dim['Educacion'][p]=casen_tip_dim['Asistencia'][p]+casen_tip_dim['Rezago escolar'][p]+casen_tip_dim['Escolaridad'][p]
  casen_tip_dim['Salud'][p]=casen_tip_dim['Malnutricion infantil'][p]+casen_tip_dim['Sistema de salud'][p]+casen_tip_dim['Atencion'][p]
  casen_tip_dim['Trabajo y seguridad social'][p]=casen_tip_dim['Ocupacion'][p]+casen_tip_dim['Seguridad social'][p]+casen_tip_dim['Jubilaciones'][p]
  casen_tip_dim['Vivienda y entorno'][p]=casen_tip_dim['Habitabilidad'][p]+casen_tip_dim['Servicios basicos'][p]+casen_tip_dim['Entorno'][p]
  casen_tip_dim['Redes y cohesion social'][p]=casen_tip_dim['Apoyo y participacion social'][p]+casen_tip_dim['Trato igualitario'][p]+casen_tip_dim['Seguridad'][p]


casen_tip_dim=casen_tip_dim[[f1,f2,"Educacion","Salud","Trabajo y seguridad social","Vivienda y entorno","Redes y cohesion social"]]
casen_tip_dim.head()

```

```{python}
#  tipologias por carencias
tipos1=casen_tip.copy()
total1=len(tipos1[jjj].drop_duplicates().index)
print("total tipos =",total1)
tipos11=casen_hogares.groupby(["Asistencia","Rezago escolar","Escolaridad","Malnutricion infantil","Sistema de salud","Atencion","Ocupacion","Seguridad social","Jubilaciones","Habitabilidad","Servicios basicos","Entorno","Apoyo y participacion social","Trato igualitario","Seguridad"]).size()
tipos11.to_excel(excel_writer = "tipologias.xlsx")

```

```{python}
# tipologias por peso dimensional
print("total tipos =",len(casen_tip_dim.drop_duplicates().index))
tiposdim2=casen_tip_dim.groupby(["Educacion","Salud","Trabajo y seguridad social","Vivienda y entorno","Redes y cohesion social"]).size()
tiposdim2.to_excel(excel_writer = "tipologias_dimensionales.xlsx")
```

```{python}
# tipologías por cuantiles

# paso 1: asignacion ponderación total
tipos2=casen_tip.copy()
tipos2["IntPob"]=np.nan
tipos2

mult1=7.5
mult2=(10/3)

for p in tipos2.index:
  c11=tipos2['Asistencia'][p]
  c12=tipos2['Rezago escolar'][p]
  c13=tipos2['Escolaridad'][p]
  c21=tipos2['Malnutricion infantil'][p]
  c22=tipos2['Sistema de salud'][p]
  c23=tipos2['Atencion'][p]
  c31=tipos2['Ocupacion'][p]
  c32=tipos2['Seguridad social'][p]
  c33=tipos2['Jubilaciones'][p]
  c41=tipos2['Habitabilidad'][p]
  c42=tipos2['Servicios basicos'][p]
  c43=tipos2['Entorno'][p]
  c51=tipos2['Apoyo y participacion social'][p]
  c52=tipos2['Trato igualitario'][p]
  c53=tipos2['Seguridad'][p]
  k=1+5+c12
  c=round(mult1*(c11+c12+c13+c21+c22+c23+c31+c32+c33+c41+c42+c43)+mult2*(c51+c52+c53),2)

  tipos2['IntPob'][p]=c
```

```{python}
# paso 2: definición cuantiles 

cuant=tipos2[["IntPob"]].quantile([.4, .6, .8, .9, 1], axis = 0)

for p in cuant.index:
  print("cuantil=",p)
  j=cuant["IntPob"][p]
  k=len(tipos2[tipos2.IntPob<=j])
  print("marca=",j)
  print("frecuencia acumulada=",k)
  print("frecuencia acumulada porcentual=",round(k*100/12392,2),"%")
  print("____________________________")
```

```{python}
m1=22.5
m2=25.83
m3=30.0
m4=33.33
m5=63.33

tipos2["marca"]=np.nan

for p in tipos2.index:
  if tipos2['IntPob'][p]<=m1:
    tipos2["marca"][p]=m1

  elif tipos2['IntPob'][p]<=m2:
    tipos2["marca"][p]=m2

  elif tipos2['IntPob'][p]<=m3:
    tipos2["marca"][p]=m3

  elif tipos2['IntPob'][p]<=m4:
    tipos2["marca"][p]=m4

  elif tipos2['IntPob'][p]<=m5:
    tipos2["marca"][p]=m5

tipos21=tipos2[tipos2.marca==m1]
tipos22=tipos2[tipos2.marca==m2]
tipos23=tipos2[tipos2.marca==m3]
tipos24=tipos2[tipos2.marca==m4]
tipos25=tipos2[tipos2.marca==m5]

acum=len(tipos21)
print("marca:",m1)
print("frecuencia:",len(tipos21))
print("frecuencia acumulada:",acum)
print("________________________________________")
acum=acum+len(tipos22)
print("marca:",m2)
print("frecuencia:",len(tipos22))
print("frecuencia acumulada:",acum)
print("________________________________________")
acum=acum+len(tipos23)
print("marca:",m3)
print("frecuencia:",len(tipos23))
print("frecuencia acumulada:",acum)
print("________________________________________")
acum=acum+len(tipos24)
print("marca:",m4)
print("frecuencia:",len(tipos24))
print("frecuencia acumulada:",acum)
print("________________________________________")
acum=acum+len(tipos25)
print("marca:",m5)
print("frecuencia:",len(tipos25))
print("frecuencia acumulada:",acum)
print("________________________________________")
```

```{python}
jjj=["Asistencia","Rezago escolar","Escolaridad","Malnutricion infantil","Sistema de salud","Atencion","Ocupacion","Seguridad social","Jubilaciones","Habitabilidad","Servicios basicos","Entorno","Apoyo y participacion social","Trato igualitario","Seguridad"]

# intervalo m1
total21=len(tipos21[jjj].drop_duplicates().index)
total22=len(tipos22[jjj].drop_duplicates().index)
total23=len(tipos23[jjj].drop_duplicates().index)
total24=len(tipos24[jjj].drop_duplicates().index)
total25=len(tipos25[jjj].drop_duplicates().index)
print("total tipos =",total21+total22+total23+total24+total25)
print("total tipos m1 =",total21)
print("total tipos m2 =",total22)
print("total tipos m3 =",total23)
print("total tipos m4 =",total24)
print("total tipos m5 =",total25)


tipos_m1=tipos21.groupby(jjj).size()
tipos_m1.to_excel(excel_writer = "tipologias_m1.xlsx")

tipos_m2=tipos22.groupby(jjj).size()
tipos_m2.to_excel(excel_writer = "tipologias_m2.xlsx")

tipos_m3=tipos23.groupby(jjj).size()
tipos_m3.to_excel(excel_writer = "tipologias_m3.xlsx")

tipos_m4=tipos24.groupby(jjj).size()
tipos_m4.to_excel(excel_writer = "tipologias_m4.xlsx")

tipos_m5=tipos25.groupby(jjj).size()
tipos_m5.to_excel(excel_writer = "tipologias_m5.xlsx")

```

```{python}
tipos25
```

#12.1- Gráficos frecuencia carencias



```{python}
# FUNCIÓN PARA GRAFICO TIPO RADAR
 
def make_spider( df,row, title, color, max):
 
  df=df
# number of variable
  categories=list(df)[1:]
  N = len(categories)
 
# What will be the angle of each axis in the plot? (we divide the plot / number of variable)
  angles = [n / float(N) * 2 * pi for n in range(N)]
  angles += angles[:1]
 
# Initialise the spider plot
  ax = plt.subplot(3,2,row+1, polar=True, )
 
# If you want the first axis to be on top:
  ax.set_theta_offset(pi / 2)
  ax.set_theta_direction(-1)
 
# Draw one axe per variable + add labels labels yet
  plt.xticks(angles[:-1], categories, color='grey', size=8)
 
# Draw ylabels
  c1=max/4
  c2=max/2
  c3=3*max/4
  ax.set_rlabel_position(0)
  plt.yticks([c1,c2,c3], ["25%","50%","75%"], color="grey", size=7)
  plt.ylim(0,max)
 
# Ind1
  values=df.loc[row].drop('group').values.flatten().tolist()
  values += values[:1]
  ax.plot(angles, values, color=color, linewidth=2, linestyle='solid')
  ax.fill(angles, values, color=color, alpha=0.4)



 
# Add a title
  plt.title(title, size=11, color=color, y=1.1)

  return
  plt.show()

  
```

```{python}
# CALCULO FRECUENCIA DE CARENCIAS POR TIPO DE HOGAR


casen3=tipohogares.copy()
casen3=casen3.drop("folio",axis=1)


grouped_casen3 = casen3.groupby(["d"])
suma_casen3 = grouped_casen3.sum()
suma_casen3 = suma_casen3.reset_index()

suma_casen3['group']=np.nan
suma_casen3.loc[suma_casen3["d"] == 1, 'group'] = "unipersonal" 
suma_casen3.loc[suma_casen3["d"] == 2, 'group'] = "monoparental nuclear" 
suma_casen3.loc[suma_casen3["d"] == 3, 'group'] = "biparental nuclear" 
suma_casen3.loc[suma_casen3["d"] == 4, 'group'] = "monoparental extendido" 
suma_casen3.loc[suma_casen3["d"] == 5, 'group'] = "biparental extendido" 
suma_casen3.loc[suma_casen3["d"] == 6, 'group'] = "censal" 

spider1=suma_casen3.drop("d", axis=1)
spider1

ttt = spider1.pop("group")
spider1.insert(0, "group", ttt)
spider1
```

```{python}
# CALCULO FRECUENCIA DE CARENCIAS AGRUPADAS POR DIMENSION Y TIPO DE HOGAR
dim3=dim1.copy()
dim31=dim3[dim3.d==1]
dim32=dim3[dim3.d==2]
dim33=dim3[dim3.d==3]
dim34=dim3[dim3.d==4]
dim35=dim3[dim3.d==5]
dim36=dim3[dim3.d==6]
#############################

casen4=dim3.copy()
casen4=casen4.drop("folio",axis=1)


grouped_casen4 = casen4.groupby(["d"])
suma_casen4 = grouped_casen4.sum()
suma_casen4 = suma_casen4.reset_index()

suma_casen4['group']=np.nan
suma_casen4.loc[suma_casen4["d"] == 1, 'group'] = "unipersonal" 
suma_casen4.loc[suma_casen4["d"] == 2, 'group'] = "monoparental nuclear" 
suma_casen4.loc[suma_casen4["d"] == 3, 'group'] = "biparental nuclear" 
suma_casen4.loc[suma_casen4["d"] == 4, 'group'] = "monoparental extendido" 
suma_casen4.loc[suma_casen4["d"] == 5, 'group'] = "biparental extendido" 
suma_casen4.loc[suma_casen4["d"] == 6, 'group'] = "censal" 

spider2=suma_casen4.drop("d", axis=1)
spider2

tttt = spider2.pop("group")
spider2.insert(0, "group", tttt)
spider2
```

```{python}
# EJECUCIÓN RADAR 1
# initialize the figure
my_dpi=96
plt.figure(figsize=(1000/my_dpi, 1000/my_dpi), dpi=my_dpi)
 
# Create a color palette:
my_palette = plt.cm.get_cmap("Set2", len(spider1.index))
 
# Loop to plot

for row in range(0, len(spider1.index)):

  if spider1["group"][row]=="unipersonal":
    aaa=len(tipohogares.loc[tipohogares["d"] == 1].index)
  elif spider1["group"][row]=="monoparental nuclear":
    aaa=len(tipohogares.loc[tipohogares["d"] == 2].index)
  elif spider1["group"][row]=="biparental nuclear":
    aaa=len(tipohogares.loc[tipohogares["d"] == 3].index)
  elif spider1["group"][row]=="monoparental extendido":
    aaa=len(tipohogares.loc[tipohogares["d"] == 4].index)
  elif spider1["group"][row]=="biparental extendido":
    aaa=len(tipohogares.loc[tipohogares["d"] == 5].index)
  elif spider1["group"][row]=="censal":
    aaa=len(tipohogares.loc[tipohogares["d"] == 6].index)

  make_spider(spider1, row=row, title='Hogar '+spider1['group'][row], color=my_palette(row),max=aaa)
  
```

```{python}
# EJECUCIÓN RADAR 2
# initialize the figure
my_dpi=96
plt.figure(figsize=(1000/my_dpi, 1000/my_dpi), dpi=my_dpi)
 
# Create a color palette:
my_palette = plt.cm.get_cmap("Set2", len(spider2.index))
 
# Loop to plot

for row in range(0, len(spider2.index)):

  if spider2["group"][row]=="unipersonal":
    aaa=len(tipohogares.loc[tipohogares["d"] == 1].index)*3
  elif spider2["group"][row]=="monoparental nuclear":
    aaa=len(tipohogares.loc[tipohogares["d"] == 2].index)*3
  elif spider2["group"][row]=="biparental nuclear":
    aaa=len(tipohogares.loc[tipohogares["d"] == 3].index)*3
  elif spider2["group"][row]=="monoparental extendido":
    aaa=len(tipohogares.loc[tipohogares["d"] == 4].index)*3
  elif spider2["group"][row]=="biparental extendido":
    aaa=len(tipohogares.loc[tipohogares["d"] == 5].index)*3
  elif spider2["group"][row]=="censal":
    aaa=len(tipohogares.loc[tipohogares["d"] == 6].index)*3

  make_spider(spider2, row=row, title='Hogar '+spider2['group'][row], color=my_palette(row),max=aaa)
```

# Gráfico IPM vs Y

```{python}
#para los graficos se empleará como base el df tipos2

#plt.plot( 'IntPob', 'ypc', data=tipos2, linestyle='none', marker='o')

# Use the 'hue' argument to provide a factor variable
sb.lmplot( x="ypc", y="IntPob", data=tipos2, fit_reg=False, hue='d', legend=False)
 
# Move the legend to an empty part of the plot
plt.legend(loc='lower right')
 
#sns.plt.show()


plt.show()

#tipos2
```

